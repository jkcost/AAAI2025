
| Arguments Keep work_dir: C:\Users\JK\PycharmProjects\2025_AAAI\work_dir/dj30_AAAI_AAAI_adam_mse\2025_AAAI_Exp_None_exp_num_0725/120429
rank:None end_date:['2012-02-16']
Traceback (most recent call last):
  File "C:\Users\JK\PycharmProjects\2025_AAAI\agents\AAAI.py", line 152, in train_net
    self.scaler.scale(total_loss).backward()
  File "C:\Users\JK\anaconda3\envs\2025_AAAI_server\lib\site-packages\torch\_tensor.py", line 525, in backward
    torch.autograd.backward(
  File "C:\Users\JK\anaconda3\envs\2025_AAAI_server\lib\site-packages\torch\autograd\__init__.py", line 267, in backward
    _engine_run_backward(
  File "C:\Users\JK\anaconda3\envs\2025_AAAI_server\lib\site-packages\torch\autograd\graph.py", line 744, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: Function 'ConvolutionBackward0' returned nan values in its 0th output.