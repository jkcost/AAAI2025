2024-07-25 08:32:20,993 INFO    MainThread:45804 [wandb_setup.py:_flush():76] Current SDK version is 0.17.4
2024-07-25 08:32:20,994 INFO    MainThread:45804 [wandb_setup.py:_flush():76] Configure stats pid to 45804
2024-07-25 08:32:20,994 INFO    MainThread:45804 [wandb_setup.py:_flush():76] Loading settings from C:\Users\JK\.config\wandb\settings
2024-07-25 08:32:20,994 INFO    MainThread:45804 [wandb_setup.py:_flush():76] Loading settings from C:\Users\JK\PycharmProjects\2025_AAAI\wandb\settings
2024-07-25 08:32:20,994 INFO    MainThread:45804 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2024-07-25 08:32:20,994 INFO    MainThread:45804 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2024-07-25 08:32:20,996 INFO    MainThread:45804 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'run.py', 'program_abspath': 'C:\\Users\\JK\\PycharmProjects\\2025_AAAI\\run.py', 'program': 'C:\\Users\\JK\\PycharmProjects\\2025_AAAI\\run.py'}
2024-07-25 08:32:20,996 INFO    MainThread:45804 [wandb_setup.py:_flush():76] Applying login settings: {}
2024-07-25 08:32:20,996 INFO    MainThread:45804 [wandb_init.py:_log_setup():529] Logging user logs to C:\Users\JK\PycharmProjects\2025_AAAI\wandb\run-20240725_083220-j1o6gcaf\logs\debug.log
2024-07-25 08:32:20,996 INFO    MainThread:45804 [wandb_init.py:_log_setup():530] Logging internal logs to C:\Users\JK\PycharmProjects\2025_AAAI\wandb\run-20240725_083220-j1o6gcaf\logs\debug-internal.log
2024-07-25 08:32:20,996 INFO    MainThread:45804 [wandb_init.py:init():569] calling init triggers
2024-07-25 08:32:20,997 INFO    MainThread:45804 [wandb_init.py:init():576] wandb.init called with sweep_config: {}
config: {}
2024-07-25 08:32:20,997 INFO    MainThread:45804 [wandb_init.py:init():619] starting backend
2024-07-25 08:32:20,997 INFO    MainThread:45804 [wandb_init.py:init():623] setting up manager
2024-07-25 08:32:21,000 INFO    MainThread:45804 [backend.py:_multiprocessing_setup():105] multiprocessing start_methods=spawn, using: spawn
2024-07-25 08:32:21,002 INFO    MainThread:45804 [wandb_init.py:init():631] backend started and connected
2024-07-25 08:32:21,008 INFO    MainThread:45804 [wandb_init.py:init():720] updated telemetry
2024-07-25 08:32:21,010 INFO    MainThread:45804 [wandb_init.py:init():753] communicating run to backend with 90.0 second timeout
2024-07-25 08:32:21,496 INFO    MainThread:45804 [wandb_run.py:_on_init():2402] communicating current version
2024-07-25 08:32:21,524 INFO    MainThread:45804 [wandb_run.py:_on_init():2411] got version response upgrade_message: "wandb version 0.17.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2024-07-25 08:32:21,524 INFO    MainThread:45804 [wandb_init.py:init():804] starting run threads in backend
2024-07-25 08:32:21,842 INFO    MainThread:45804 [wandb_run.py:_console_start():2380] atexit reg
2024-07-25 08:32:21,842 INFO    MainThread:45804 [wandb_run.py:_redirect():2235] redirect: wrap_raw
2024-07-25 08:32:21,842 INFO    MainThread:45804 [wandb_run.py:_redirect():2300] Wrapping output streams.
2024-07-25 08:32:21,842 INFO    MainThread:45804 [wandb_run.py:_redirect():2325] Redirects installed.
2024-07-25 08:32:21,845 INFO    MainThread:45804 [wandb_init.py:init():847] run started, returning control to user process
2024-07-25 08:32:21,847 INFO    MainThread:45804 [wandb_run.py:_config_callback():1382] config_cb None None {'_cfg_dict': {'common_params': {'initial_amount': 100000, 'transaction_cost_pct': 0.001, 'tech_indicator_list': ['high', 'low', 'open', 'close', 'adjcp', 'zopen', 'zhigh', 'zlow', 'zadjcp', 'zclose', 'zd_5', 'zd_10', 'zd_15', 'zd_20', 'zd_25', 'zd_30'], 'temperature': 1, 'timesteps': 5, 'batch_size': 64, 'num_epochs': 10, 'length_day': 10, 'seq_len': 20, 'label_len': 5, 'pred_len': 5, 'model': 'Transformer', 'wandb_project_name': '2025_AAAI_Exp', 'wandb_group_name': 'main_exp', 'wandb_session_name': 'exp_num', 'gpu_ids': [0, 1, 2, 3, 4, 5], 'lr': 1e-05, 'norm_method': 'date'}, 'dataset_name': 'dj30', 'net_name': 'AAAI', 'agent_name': 'AAAI', 'optimizer_name': 'adam', 'loss_name': 'mse', 'work_dir': 'work_dir/dj30_AAAI_AAAI_adam_mse', 'batch_size': 64, 'wandb_project_name': ['2025_AAAI_Exp'], 'wandb_group_name': ['main_exp'], 'wandb_session_name': ['exp_num'], 'gpu_ids': [0, 1, 2, 3, 4, 5], 'data': {'type': 'AAAIDataset', 'data_path': 'data/dj30', 'train_path': 'train.csv', 'valid_path': 'valid.csv', 'test_path': 'test.csv', 'test_dynamic_path': 'test_with_label.csv', 'tech_indicator_list': ['high', 'low', 'open', 'close', 'adjcp', 'zopen', 'zhigh', 'zlow', 'zadjcp', 'zclose', 'zd_5', 'zd_10', 'zd_15', 'zd_20', 'zd_25', 'zd_30'], 'size': [20, 5, 5], 'features': 'MS', 'scale': True, 'timeenc': 1, 'freq': 'D', 'length_day': 10, 'timesteps': 5, 'initial_amount': 100000, 'transaction_cost_pct': 0.001}, 'environment': {'type': 'AAAIEnvironment'}, 'transition': {'type': 'Transition'}, 'agent': {'type': 'AAAI', 'memory_capacity': 1000, 'gamma': 0.99, 'policy_update_frequency': 500, 'timesteps': 5}, 'trainer': {'type': 'AAAI_reinforce', 'pred_len': 5, 'epochs': 10, 'gamma': 0.05, 'work_dir': 'work_dir/dj30_AAAI_AAAI_adam_mse', 'if_remove': False, 'wandb_project_name': '2025_AAAI_Exp', 'wandb_group_name': 'main_exp', 'wandb_session_name': 'exp_num', 'temperature': 1}, 'loss': {'type': 'MSELoss'}, 'optimizer': {'type': 'Adam', 'lr': 1e-05}, 'act_net': {'type': 'AAAI', 'attention_bool': 'True', 'model': 'Transformer', 'dropout': 0.5, 'num_stocks': 29, 'seq_len': 20, 'label_len': 5, 'pred_len': 5, 'modes': 64, 'enc_in': 16, 'dec_in': 16, 'c_out': 16, 'd_model': 256, 'n_heads': 4, 'e_layers': 2, 'd_layers': 1, 'output_attention': True, 'embed': 'timeF', 'freq': 'd', 'factor': 1, 'd_ff': 512, 'activation': 'gelu', 'use_norm': True}}, '_filename': 'C:\\Users\\JK\\PycharmProjects\\2025_AAAI\\configs\\dj30_AAAI.py', '_text': 'import os\nimport sys\nsys.path.insert(0, os.path.dirname(__file__))\nfrom configs.common_config  import common_params\n\n\n# task_name = "portfolio_management"\ndataset_name = "dj30"\nnet_name = "AAAI"\nagent_name = "AAAI"\noptimizer_name = "adam"\nloss_name = "mse"\nwork_dir = f"work_dir/{dataset_name}_{net_name}_{agent_name}_{optimizer_name}_{loss_name}"\n\n# _base_ = [\n#     f"../_base_/datasets/{task_name}/{dataset_name}.py",\n#     f"../_base_/environments/{task_name}/env.py",\n#     f"../_base_/agents/{task_name}/{agent_name}.py",\n#     f"../_base_/trainers/{task_name}/deeptrader_trainer.py",\n#     f"../_base_/losses/{loss_name}.py",\n#     f"../_base_/optimizers/{optimizer_name}.py",\n#     f"../_base_/nets/{net_name}.py",\n#     f"../_base_/transition/transition.py"\n# ]\nbatch_size = 64\nwandb_project_name =common_params[\'wandb_project_name\'],\nwandb_group_name =common_params[\'wandb_group_name\'],\nwandb_session_name =common_params[\'wandb_session_name\'],\ngpu_ids = common_params[\'gpu_ids\']\ndata = dict(\n    type=\'AAAIDataset\',\n    data_path=\'data/dj30\',\n    train_path=\'train.csv\',\n    valid_path=\'valid.csv\',\n    test_path=\'test.csv\',\n    test_dynamic_path=\'test_with_label.csv\',\n    tech_indicator_list= common_params[\'tech_indicator_list\'],\n    size=[common_params[\'seq_len\'], common_params[\'label_len\'], common_params[\'pred_len\']],\n    features = \'MS\',\n    scale = True,\n    timeenc = 1,\n    freq = \'D\',\n    length_day=common_params[\'length_day\'],\n    timesteps=common_params[\'timesteps\'],\n    initial_amount=common_params[\'initial_amount\'],\n    transaction_cost_pct=common_params[\'transaction_cost_pct\'])\n\nenvironment = dict(type=\'AAAIEnvironment\')\n\ntransition = dict(\n    type = "Transition"\n)\nagent = dict(\n    type=\'AAAI\',\n    memory_capacity=1000,\n    gamma=0.99,\n    policy_update_frequency=500,timesteps=5)\n\ntrainer = dict(\n    type=\'AAAI_reinforce\',\n    pred_len = common_params[\'pred_len\'],\n    epochs=common_params[\'num_epochs\'],\n    gamma = 0.05,\n    work_dir=work_dir,\n    if_remove=False,\n    wandb_project_name =common_params[\'wandb_project_name\'],\n    wandb_group_name =common_params[\'wandb_group_name\'],\n    wandb_session_name =common_params[\'wandb_session_name\'],\n    temperature = common_params[\'temperature\'])\n\nloss = dict(type=\'MSELoss\')\noptimizer = dict(type=\'Adam\', lr=common_params[\'lr\'])\n\nact_net = dict(\n    type=\'AAAI\',\n    attention_bool=\'True\',\n    model = common_params[\'model\'],\n    dropout = 0.5,\n    num_stocks = 29,\n    seq_len = common_params[\'seq_len\'],\n    label_len = common_params[\'label_len\'],\n    pred_len = common_params[\'pred_len\'],\n    modes = 64,\n    enc_in = 16,\n    dec_in = 16,\n    c_out = 16,\n    d_model = 256,\n    n_heads = 4,\n    e_layers = 2,\n    d_layers = 1,\n    output_attention = True,\n    embed= \'timeF\',\n    freq = \'d\',\n    factor = 1,\n    d_ff = 512,\n    activation = \'gelu\',\n    use_norm = True)\n\n\n\n\n\n\n\n\n'}
2024-07-25 08:34:50,551 WARNING MsgRouterThr:45804 [router.py:message_loop():77] message_loop has been closed
